{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPD2V7+ZEqalDiMR5YBFsJc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/golna001/visualwakewords/blob/master/MNIST_classification_small_wNoise_customLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install brevitas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DssngY_p8OUB",
        "outputId": "dbb52b72-968e-4de2-a04d-5c4caf192f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting brevitas\n",
            "  Downloading brevitas-0.9.1-py3-none-any.whl (411 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/411.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m317.4/411.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.4/411.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dependencies==2.0.1 (from brevitas)\n",
            "  Downloading dependencies-2.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brevitas) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from brevitas) (67.7.2)\n",
            "Requirement already satisfied: torch>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from brevitas) (2.0.1+cu118)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from brevitas) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.1->brevitas) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.1->brevitas) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.1->brevitas) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.1->brevitas) (1.3.0)\n",
            "Installing collected packages: dependencies, brevitas\n",
            "Successfully installed brevitas-0.9.1 dependencies-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPb_wwCyyI5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1386ce30-ec8b-42f1-fce9-9a1249630dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from brevitas.quant import IntBias  as BiasQuant\n",
        "import brevitas.nn as qnn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "batch_size = 16\n",
        "nbits = 4\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./dataMNIST', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./dataMNIST', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "sample = next(iter(trainloader))\n",
        "image, label = sample\n",
        "print(image.shape)\n",
        "\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
      ],
      "metadata": {
        "id": "H8Axs3vBy7Wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d29a6e5-154e-44d3-c2cd-edf405c02751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./dataMNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 83005830.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataMNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./dataMNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./dataMNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 76814010.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataMNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./dataMNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./dataMNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 23186214.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataMNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./dataMNIST/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./dataMNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13946214.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataMNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataMNIST/MNIST/raw\n",
            "\n",
            "torch.Size([16, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train and test ratio\n",
        "len(trainloader)/(len(trainloader)+len(testloader))"
      ],
      "metadata": {
        "id": "tYNkk23_vDi6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title some data visualization\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "7Ofw9QcfzHDK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianNoise(nn.Module):\n",
        "    def __init__(self, std=None):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "\n",
        "    def forward(self, x, scale, kernel_size, input_channel):\n",
        "        if self.std is not None and self.std != 0.0:\n",
        "            noise = torch.randn(x.size()) * self.std * scale * kernel_size * np.sqrt(input_channel)\n",
        "            x = x + noise\n",
        "        return x\n",
        "\n",
        "class LayerDiffStd(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "    def forward(self, x1, x2):\n",
        "      return torch.std(torch.sub(x1, x2))\n",
        "\n",
        "# My quantized model\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # super(QNet, self).__init__()\n",
        "        super().__init__()\n",
        "\n",
        "        self.identity = qnn.QuantIdentity(bit_width=nbits,\n",
        "                                          signed=False,\n",
        "                                          return_quant_tensor=True)\n",
        "\n",
        "        self.noise_module = GaussianNoise(None)\n",
        "\n",
        "        self.conv1 = qnn.QuantConv2d(in_channels=1,\n",
        "                                     out_channels=10,\n",
        "                                     kernel_size=3,\n",
        "                                     weight_bit_width=nbits,\n",
        "                                     bias_quant=BiasQuant,\n",
        "                                     bias_bit_width=nbits,\n",
        "                                     return_quant_tensor=True)\n",
        "        self.conv2 = qnn.QuantConv2d(in_channels=10,\n",
        "                                     out_channels=16,\n",
        "                                     kernel_size=3,\n",
        "                                     weight_bit_width=nbits,\n",
        "                                     bias_quant=BiasQuant,\n",
        "                                     bias_bit_width=nbits,\n",
        "                                     return_quant_tensor=True)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.relu = qnn.QuantReLU(bit_width=nbits, return_quant_tensor=True)\n",
        "\n",
        "        self.dropout2 = nn.Dropout2d()\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        self.fc1 = qnn.QuantLinear(in_features=400,\n",
        "                                   out_features=50,\n",
        "                                   bias=True,\n",
        "                                   weight_bit_width=nbits,\n",
        "                                   bias_quant=BiasQuant,\n",
        "                                   bias_bit_width=nbits)\n",
        "        self.fc2 = qnn.QuantLinear(in_features=50,\n",
        "                                   out_features=10,\n",
        "                                   bias=False,\n",
        "                                   weight_bit_width=nbits,\n",
        "                                   bias_quant=BiasQuant,\n",
        "                                   bias_bit_width=nbits)\n",
        "        self.lds = LayerDiffStd()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.identity(x)\n",
        "        out = self.conv1(out)\n",
        "        # print(out)\n",
        "        out1 = self.noise_module(out,\n",
        "                                out.scale.cpu().detach().numpy()[0][0][0][0],\n",
        "                                self.conv1.kernel_size[0],\n",
        "                                self.conv1.in_channels)\n",
        "        # print(out1)\n",
        "        # dif = self.lds(out1, out)\n",
        "        # print(dif)\n",
        "        out = self.maxpool(out1)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.noise_module(out,\n",
        "                                out.scale.cpu().detach().numpy()[0][0][0][0],\n",
        "                                self.conv2.kernel_size[0],\n",
        "                                self.conv2.in_channels)\n",
        "        out = self.dropout2(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = out.view(-1, 400)\n",
        "\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return F.log_softmax(out, dim = 1)\n",
        "\n",
        "    def set_noise_level(self, noise_level):\n",
        "        self.noise_module.std = noise_level\n",
        "\n",
        "net = QNet()"
      ],
      "metadata": {
        "id": "PxHc2qrqya-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.7)\n",
        "train_noise = 10\n",
        "eval_noise = 10"
      ],
      "metadata": {
        "id": "WeUsii9AzwwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    net.set_noise_level(train_noise)\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIVQ1bBMz4DR",
        "outputId": "bbcabd3b-f47a-4250-b40d-273e2557ce1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 2.306\n",
            "[1,   400] loss: 2.300\n",
            "[1,   600] loss: 2.299\n",
            "[1,   800] loss: 2.298\n",
            "[1,  1000] loss: 2.294\n",
            "[1,  1200] loss: 2.287\n",
            "[1,  1400] loss: 2.283\n",
            "[1,  1600] loss: 2.277\n",
            "[1,  1800] loss: 2.264\n",
            "[1,  2000] loss: 2.247\n",
            "[1,  2200] loss: 2.242\n",
            "[1,  2400] loss: 2.209\n",
            "[1,  2600] loss: 2.174\n",
            "[1,  2800] loss: 2.137\n",
            "[1,  3000] loss: 2.069\n",
            "[1,  3200] loss: 2.004\n",
            "[1,  3400] loss: 1.905\n",
            "[1,  3600] loss: 1.833\n",
            "[2,   200] loss: 1.666\n",
            "[2,   400] loss: 1.573\n",
            "[2,   600] loss: 1.481\n",
            "[2,   800] loss: 1.431\n",
            "[2,  1000] loss: 1.362\n",
            "[2,  1200] loss: 1.342\n",
            "[2,  1400] loss: 1.253\n",
            "[2,  1600] loss: 1.190\n",
            "[2,  1800] loss: 1.154\n",
            "[2,  2000] loss: 1.110\n",
            "[2,  2200] loss: 1.098\n",
            "[2,  2400] loss: 1.065\n",
            "[2,  2600] loss: 1.021\n",
            "[2,  2800] loss: 0.985\n",
            "[2,  3000] loss: 0.981\n",
            "[2,  3200] loss: 0.947\n",
            "[2,  3400] loss: 0.925\n",
            "[2,  3600] loss: 0.921\n",
            "[3,   200] loss: 0.858\n",
            "[3,   400] loss: 0.851\n",
            "[3,   600] loss: 0.830\n",
            "[3,   800] loss: 0.861\n",
            "[3,  1000] loss: 0.820\n",
            "[3,  1200] loss: 0.825\n",
            "[3,  1400] loss: 0.822\n",
            "[3,  1600] loss: 0.821\n",
            "[3,  1800] loss: 0.781\n",
            "[3,  2000] loss: 0.734\n",
            "[3,  2200] loss: 0.792\n",
            "[3,  2400] loss: 0.775\n",
            "[3,  2600] loss: 0.706\n",
            "[3,  2800] loss: 0.754\n",
            "[3,  3000] loss: 0.746\n",
            "[3,  3200] loss: 0.736\n",
            "[3,  3400] loss: 0.713\n",
            "[3,  3600] loss: 0.709\n",
            "[4,   200] loss: 0.690\n",
            "[4,   400] loss: 0.718\n",
            "[4,   600] loss: 0.661\n",
            "[4,   800] loss: 0.688\n",
            "[4,  1000] loss: 0.673\n",
            "[4,  1200] loss: 0.703\n",
            "[4,  1400] loss: 0.681\n",
            "[4,  1600] loss: 0.715\n",
            "[4,  1800] loss: 0.679\n",
            "[4,  2000] loss: 0.660\n",
            "[4,  2200] loss: 0.645\n",
            "[4,  2400] loss: 0.611\n",
            "[4,  2600] loss: 0.634\n",
            "[4,  2800] loss: 0.666\n",
            "[4,  3000] loss: 0.637\n",
            "[4,  3200] loss: 0.622\n",
            "[4,  3400] loss: 0.593\n",
            "[4,  3600] loss: 0.629\n",
            "[5,   200] loss: 0.620\n",
            "[5,   400] loss: 0.609\n",
            "[5,   600] loss: 0.611\n",
            "[5,   800] loss: 0.588\n",
            "[5,  1000] loss: 0.605\n",
            "[5,  1200] loss: 0.578\n",
            "[5,  1400] loss: 0.591\n",
            "[5,  1600] loss: 0.587\n",
            "[5,  1800] loss: 0.628\n",
            "[5,  2000] loss: 0.579\n",
            "[5,  2200] loss: 0.591\n",
            "[5,  2400] loss: 0.580\n",
            "[5,  2600] loss: 0.540\n",
            "[5,  2800] loss: 0.592\n",
            "[5,  3000] loss: 0.582\n",
            "[5,  3200] loss: 0.606\n",
            "[5,  3400] loss: 0.561\n",
            "[5,  3600] loss: 0.551\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title prediction visualization 1\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "oPV1nGAo0KnZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title prediction visualization 2\n",
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "4QOHtUXO1S3l",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy of train\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "net.set_noise_level(eval_noise)\n",
        "net.eval()\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the {len(trainloader)} train images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBl2RKysDAy4",
        "outputId": "8836d47c-6fd0-43a9-bce7-cf111b1dd3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 3750 train images: 91 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy of test\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "net.set_noise_level(eval_noise)\n",
        "net.eval()\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the {len(testloader)} test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xn5DeSt_1y1x",
        "outputId": "41b8af35-de21-4275-c6af-0d6775d3fc22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-9d8734b27fc8>:15: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:363.)\n",
            "  return torch.std(torch.sub(x1, x2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n",
            "tensor(0.0024)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b284f112f436>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# calculate outputs by running images through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# the class with the highest energy is what we choose as prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-9d8734b27fc8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         out = self.noise_module(out,\n\u001b[1;32m     80\u001b[0m                                 \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brevitas/nn/quant_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuantTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuantTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_bias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brevitas/nn/quant_layer.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CachedIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             output_tensor = self.inner_forward_impl(\n\u001b[0m\u001b[1;32m    321\u001b[0m                 quant_input.value, quant_weight.value, quant_bias.value)\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brevitas/nn/quant_conv.py\u001b[0m in \u001b[0;36minner_forward_impl\u001b[0;34m(self, x, quant_weight, quant_bias)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_bias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'standard'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_zeros_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_same_zeros_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brevitas/nn/quant_conv.py\u001b[0m in \u001b[0;36mconv2d_zeros_pad\u001b[0;34m(self, x, weight, bias)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconv2d_zeros_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxTmt62XbIND",
        "outputId": "7023a04d-399f-4713-d264-d9b5413fbad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK_lGqUW1626",
        "outputId": "dea778bc-15d6-4380-8547-3d2d3beec60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class: 0     is 99.1 %\n",
            "Accuracy for class: 1     is 99.3 %\n",
            "Accuracy for class: 2     is 96.4 %\n",
            "Accuracy for class: 3     is 98.3 %\n",
            "Accuracy for class: 4     is 98.1 %\n",
            "Accuracy for class: 5     is 96.9 %\n",
            "Accuracy for class: 6     is 97.7 %\n",
            "Accuracy for class: 7     is 96.5 %\n",
            "Accuracy for class: 8     is 93.9 %\n",
            "Accuracy for class: 9     is 96.4 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'MNIST_smallmodel'+'_'+str(nbits)+'bits.pkl'\n",
        "torch.save(net.state_dict(), model_name)"
      ],
      "metadata": {
        "id": "7-peBDUvusLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.load('MNIST_model.pth')\n",
        "model = torch.load('MNIST_smallmodel_4bits.pkl')\n",
        "print(model)"
      ],
      "metadata": {
        "id": "3DtLGaQJx_hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "Rlr-FchlzCFG"
      }
    }
  ]
}